# 1-感受野

The **receptive field** is defined as the region in the input space that a particular CNN’s feature is looking at (i.e. be affected by).

**感受野（Receptive Field），指的是神经网络中神经元“看到的”输入区域，在卷积神经网络中，feature map上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。**

卷积神经网络中，越深层的神经元看到的输入区域越大，如下图所示，kernel size 均为3×3，stride均为1，绿色标记的是Layer2每个神经元看到的区域，黄色标记的是Layer3 看到的区域，具体地，Layer2每个神经元可看到Layer1 上 3×3 大小的区域，Layer3 每个神经元看到Layer2 上 3×3 大小的区域，该区域可以又看到Layer1 上 5×5 （因为layer2的3x3是在layer5x5的区域上用3x3卷积核计算得到）大小的区域。

![https://www.researchgate.net/publication/316950618_Maritime_Semantic_Labeling_of_Optical_Remote_Sens](https://s2.ax1x.com/2019/12/16/Q4wXPf.png)

所以，**感受野是个相对概念，某层feature map上的元素看到前面不同层上的区域范围是不同的，通常在不特殊指定的情况下，感受野指的是看到输入图像上的区域。**





# 2--围棋  playout

在引入深度学习之前的mcts方法中，如早期的Zen，一个playout指从当前盘面开始，经过一次快速模拟走子直到终局，获得一个胜负结果的过程。
在引入深度学习方法后的早期阶段，如AlphaGo Fan和AlphaGo  Lee架构，一个playout指从当前盘面开始，经过一次对神经网络中的价值网络访问获得一个局面评估值，及从该盘面进行1000次快速模拟走子（称为rollout）获取统计结果，并将上两项加权相加，得出该盘面最终评估的过程。
在后续的深度学习方法，如AlphaGo Zero和Alpha Zero架构，一个playout指从当前盘面，获得一个神经网络的value端（价值网络）评估输出值的过程。
一般可以简单翻译为计算量（次数），或模拟量（次数）。



# 3--TensorFlow Lite

TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 loT 设备上运行模型，以便实现设备端机器学习。

### 主要特性

通过解决以下 5 项约束条件，针对设备端机器学习进行了优化：延时（数据无需往返服务器）、隐私（没有任何个人数据离开设备）、连接性（无需连接互联网）、大小（缩减了模型和二进制文件的大小）和功耗（高效推断，且无需网络连接）。

支持多种平台，涵盖 [Android](https://tensorflow.google.cn/lite/guide/android) 和 [iOS](https://tensorflow.google.cn/lite/guide/ios) 设备、[嵌入式 Linux](https://tensorflow.google.cn/lite/guide/python) 和[微控制器](https://tensorflow.google.cn/lite/microcontrollers)。

支持多种语言，包括 Java、Swift、Objective-C、C++ 和 Python。

高性能，支持[硬件加速](https://tensorflow.google.cn/lite/performance/delegates)和[模型优化](https://tensorflow.google.cn/lite/performance/model_optimization)。

提供多种平台上的常见机器学习任务的端到端[示例](https://tensorflow.google.cn/lite/examples)，例如图像分类、对象检测、姿势估计、问题回答、文本分类等。



# 4--TensorFlow Lite 转换器





# 2021-10-08

## 1、tf.variable_scope()

tf.variable_scope(): 可以让变量有相同的命名，包括tf.get_variable得到的变量，还有tf.Variable变量

它返回的是一个用于定义创建variable(层)的op的上下文管理器。

参考：https://blog.csdn.net/YZXnuaa/article/details/79030501



## 2、批归一化



# 2021-10-09

## 早

使用mobilenet来训练围棋的识别，测试其效果

### 研究使用CNN替代FC的可能性（在围棋中）



## 下午

### Squeeze-and-Excitation Networks

SENet的提出动机非常简单，传统的方法是将网络的Feature Map等权重的传到下一层，SENet的核心思想在于**建模通道之间的相互依赖关系，通过网络的全局损失函数自适应的重新矫正通道之间的特征相应强度**。



### mAP

mAP 是 **Mean Average Precision** 的缩写，即 **均值平均精度**。作为 **object dection** 中衡量**检测精度**的指标。计算公式为：

**mAP = 所有类别的平均精度求和除以所有类别**。

P-R曲线

P 代表 **precision**，即准确率，准确率表示**预测样本中实际正样本数占所有正样本数的比例**

R 代表 **recall** ，即召回率，召回率表示**预测样本中实际正样本数占所有预测的样本的比例**



### benchmark_model模型推理速度分析

在深度学习模型工程落地时，我们追求在成本可控的前提下提高良好的用户体验，因此模型的推理效率和计算代价是重要的衡量指标。通常用FLOPs（floating point  operations）描述模型的计算力消耗，它表示**浮点运算计算量**，用来衡量算法/模型的复杂度。我们是可以从原理上计算出模型需要的FLOPs，参考：https://www.zhihu.com/question/65305385。 除了从理论计算之外，还可以使用tensorflow中的 benchmark_model  工具来进行粗略估计，它可以帮助估算出模型所需的浮点操作数(FLOPS)，然后你就可以使用这些信息来确定你的模型在你的目标设备上运行的可行性。除此之外，比较容易混淆的概念是FLOPS（floating point operations per second），意指每秒**浮点运算次数，理解为计算速度**，它是衡量硬件性能的指标对于来说TESLA  P40可以每秒处理12T个FLOP，普通单核CPU每秒大概处理100亿次的FLOP。当有了计算操作消耗的估计之后，它就对你计划的目标设备上有所帮助，如果模型的计算操作太多，那么就需要优化模型减小FLOP数量。

在使用benchmark_model之前，需要使用tensorflow源码进行编译。

### summarize_graph 模型大小分析

服务端深度模型落地时主要关注模型的预测效率，移动端模型落地需要考虑模型的大小。通过summarize_graph工具可以帮助我们简要分析模型的参数量和包含哪些op。设置--print_structure=true可以观察到模型的结构，这也可以通过tensorboard来可视化实现。

参考：https://blog.csdn.net/weixin_39734493/article/details/111109331



### TensorFlow Lite

参考：https://tensorflow.google.cn/lite

#### 谷歌colab

参考：https://colab.research.google.com/drive/

XNNPACK



TFLite Support

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009153613686.png" alt="image-20211009153613686" style="zoom:80%;" />

Android 案例

https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android#0

4步应用讲解

https://colab.research.google.com/drive/1sqBewUnvdATOO-yblj55EBFb2sM24XHR#scrollTo=oxU2fDr-t2Ya



<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009161233556.png" alt="image-20211009161233556" style="zoom:50%;" />

#### TFLite 4大组件

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009191918104.png" alt="image-20211009191918104" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192009488.png" alt="image-20211009192009488" style="zoom:67%;" />



<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192040879.png" alt="image-20211009192040879" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192111527.png" alt="image-20211009192111527" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192140952.png" alt="image-20211009192140952" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192203463.png" alt="image-20211009192203463" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192248143.png" alt="image-20211009192248143" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192305871.png" alt="image-20211009192305871" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192338799.png" alt="image-20211009192338799" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192355014.png" alt="image-20211009192355014" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192419038.png" alt="image-20211009192419038" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009192503439.png" alt="image-20211009192503439" style="zoom:67%;" />



#### TFLite object detection API  目标检测API

参考：https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/



#### TFLite 模型优化工具  MOT

##### 量化

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200137897.png" alt="image-20211009200137897" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200302597.png" alt="image-20211009200302597" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200341639.png" alt="image-20211009200341639" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200417654.png" alt="image-20211009200417654" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200432126.png" alt="image-20211009200432126" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200511886.png" alt="image-20211009200511886" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200607518.png" alt="image-20211009200607518" style="zoom: 67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200618591.png" alt="image-20211009200618591" style="zoom: 67%;" />

##### 剪枝

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200821662.png" alt="image-20211009200821662" style="zoom:80%;" />

稀疏：用0填充张量矩阵

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009200922398.png" alt="image-20211009200922398" style="zoom:80%;" />

##### 权重聚集

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201132949.png" style="zoom:80%;" />

#### TFLite delegates   硬件加速器

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201655648.png" alt="image-20211009201655648" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201731862.png" alt="image-20211009201731862" style="zoom:50%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201808589.png" alt="image-20211009201808589" style="zoom:50%;" />

![image-20211009201853848](C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201853848.png)



![image-20211009201921728](C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201921728.png)

![image-20211009201942661](C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009201942661.png)

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202019612.png" alt="image-20211009202019612" style="zoom:50%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202031363.png" alt="image-20211009202031363" style="zoom:50%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202136870.png" alt="image-20211009202136870" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202227173.png" alt="image-20211009202227173" style="zoom:67%;" />



<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202249536.png" alt="image-20211009202249536" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202307295.png" alt="image-20211009202307295" style="zoom:67%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211009202347365.png" alt="image-20211009202347365" style="zoom:67%;" />





### 手动安装.whl工具包

1、下载好.whl包，要和环境的python版本一致

2、终端切换到下载目录下，pip install  xxx.whl

pip安装第三方库报错SSL: CERTIFICATE_VERIFY_FAILED

解决：	pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org  --upgrade  uwsgi







# 2021-10-10

## 早

### keras保存-加载训练模型

参考：https://www.tensorflow.org/tutorials/keras/save_and_load

代码资料参看D盘-TensorFlow_Lite



## 下午

### 元数据

描述数据的数据，元数据的作用是用来描述数据的

**元数据**（**Metadata**），又称**中介数据**、**中继数据**，为描述[数据](https://baike.baidu.com/item/数据/5947370)的数据（data about data），主要是描述数据[属性](https://baike.baidu.com/item/属性/1405051)（property）的[信息](https://baike.baidu.com/item/信息/111163)，用来支持如指示存储位置、[历史](https://baike.baidu.com/item/历史/360)数据、[资源](https://baike.baidu.com/item/资源/9089683)查找、文件记录等功能。



## 晚上

###  tflite_runtime 运行推理

参看：https://www.tensorflow.org/lite/inference_with_metadata/lite_support?hl=zh-cn

```python
import tensorflow as tf
```

将其改成：

```
import tflite_runtime.interpreter as tflite
```

然后更改下面一行：

```
interpreter = tf.lite.Interpreter(model_path=args.model_file)
```

将其改成：

```
interpreter = tflite.Interpreter(model_path=args.model_file)
```



### TensorFlow Lite 推理通常遵循以下4步骤：

1. **加载模型**

   您必须将`.tflite`模型加载到内存中，其中包含模型的执行图。

2. **转换数据**

   模型的原始输入数据通常与模型预期的输入数据格式不匹配。例如，您可能需要调整图像大小或更改图像格式以与模型兼容。

3. **运行推理**

   此步骤涉及使用 TensorFlow Lite API 来执行模型。它涉及几个步骤，例如构建解释器和分配张量，如以下部分所述。

4. **解释输出**

   当您收到模型推断的结果时，您必须以一种对您的应用程序有用的有意义的方式解释张量。

   例如，一个模型可能只返回一个概率列表。您可以将概率映射到相关类别并将其呈现给您的最终用户。

### 何为runtime？？

Runtime是个名词，指**某一类软件，用来为特定编程语言编写出来的程序提供支持**



[运行时（runtime）是什么意思？应该怎样深入且直观地理解？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/20607178)

https://www.zhihu.com/question/402184881



### TensorFlow Lite 模型分析器：分析给定 tflite_model 的方法

#### 模型分析器 API

```
tf.lite.experimental.Analyzer.analyze(model_path=None,# 模型路径
                                      model_content=None,# 模型对象。
                                      gpu_compatibility=False # 是否检查GPU兼容性
                                      )
```

#### 检查 GPU 委托兼容性

检查在网络设计中，是否存在某些网络节点或者某些中间张量数据使用是不受GPU数据格式支持

##### 案例一：模型不兼容时

以下代码显示了一种使用`gpu_compatibility=True`简单 tf.function 选项的方法，该选项**[`tf.slice`](https://www.tensorflow.org/api_docs/python/tf/slice)与 2D 张量一起使用并且[`tf.cosh`](https://www.tensorflow.org/api_docs/python/tf/math/cosh)**与 GPU 委托不兼容。

您将看到`GPU COMPATIBILITY WARNING`每个具有兼容性问题的节点。

```
import tensorflow as tf

@tf.function(input_signature=[
    tf.TensorSpec(shape=[4, 4], dtype=tf.float32)
])
def func(x):
  return tf.cosh(x) + tf.slice(x, [1, 1], [1, 1])

converter = tf.lite.TFLiteConverter.from_concrete_functions(
    [func.get_concrete_function()])
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS,
]
fb_model = converter.convert()

tf.lite.experimental.Analyzer.analyze(model_content=fb_model, gpu_compatibility=True)
```



###### 错误提示：

```
GPU COMPATIBILITY WARNING: Not supported custom op FlexCosh
  Op#1 SLICE(T#0, T#1, T#1) -> [T#3]
GPU COMPATIBILITY WARNING: SLICE supports for 3 or 4 dimensional tensors only, but node has 2 dimensional tensors.
  Op#2 ADD(T#2, T#3) -> [T#4]

GPU COMPATIBILITY WARNING: Subgraph#0 has GPU delegate compatibility issues at nodes 0, 1 with TFLite runtime version 2.8.0-dev20211007
```



**注意：**即使该工具没有发现任何兼容性问题，它也不能保证您的模型在每个设备上都能与 GPU 委托一起正常工作。可能会发生一些运行时不兼容的情况，例如`CL_DEVICE_IMAGE_SUPPORT`目标 OpenGL 后端缺少功能。

### tf.function 为何物？？？？？

说白了就是构建计算图

视频参考：[tf.function and Autograph (TF Dev Summit ‘19)_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1YE411t7kH?from=search&seid=4684018184620534973&spm_id_from=333.337.0.0)

将函数编译为可调用的 TensorFlow 图

参考：https://zhuanlan.zhihu.com/p/67192636

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211011134712043.png" alt="image-20211011134712043" style="zoom:50%;" />



<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211011134853495.png" alt="image-20211011134853495" style="zoom: 50%;" />

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211011135010039.png" alt="image-20211011135010039" style="zoom:50%;" />



#### 计算图构造以及运作

##### TF1---graph

对tf1.X有经验的读者应该不会对让我们又爱又恨的计算图(`tf.Graph`)和执行会话(`tf.Session`)感到陌生, 一个常规的流程如下: 

1. 初始化一个计算图并且将该计算图设置为当前scope下的默认计算图 
2. 用TF API设计计算图(比如: `y=tf.matmul(a, x) + b`) 
3. 提前界定好参数共享并划分相应的参数scope 
4. 创建并配置好`tf.Session` 
5.  将计算图传给`tf.Session`
6.   初始化参数
7.   用`tf.Session.run`来执行计算图的节点, 被执行的节点会反向追踪所有依赖的需要执行的节点并**执行计算**.

简单例子：

```python
g = tf.Graph() #初始化计算图
with g.as_default(): # 设置为默认计算图
    a = tf.constant([[10,10],[11.,1.]]) 
    x = tf.constant([[1.,0.],[0.,1.]])
    b = tf.Variable(12.)
    y = tf.matmul(a, x) + b # 描述计算图
    init_op = tf.global_variables_initializer() # 初始化待执行节点

with tf.Session() as sess: # 配置会话
    sess.run(init_op) # 执行节点
    print(sess.run(y)) # 输出结果
```

##### TF2--graph

在TF 2.0中, 由于默认为动态图, 计算会直接被执行, 也就是说, 我们不需要

- 定义计算图
- 会话执行
- 参数初始化
- 用scope定义参数分享
- 用`tf.control_dependencies`来声明节点的非直接依赖

我们可以像写普通python代码(or pytorch)一样, 写了就执行:

```python
a = tf.constant([[10,10],[11.,1.]])
x = tf.constant([[1.,0.],[0.,1.]])
b = tf.Variable(12.)
y = tf.matmul(a, x) + b
print(y.numpy())
```

一般来说, eager代码（动态图(eager execution)）会比执行相同操作的静态图代码的效率低, 因为很多计算图优化的方法只能用在数据流图上.

如果想在TF 2.0上构建传统的计算图, 我们就需要用到**`tf.function`.**

##### 函数, 而非会话

TF 2.0的其中一个重要改变就是 href="[https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md](https://link.zhihu.com/?target=https%3A//github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md)">去除tf.Session(此处应有掌声). 这个改变会迫使用户用更好的方式来组织代码: 不用再用让人纠结的`tf.Session`来执行代码, 就是一个python函数, 加上一个简单的装饰器.

在TF 2.0里面, 如果需要构建计算图, 我们只需要给python函数加上`@tf.function`的装饰器.

>  上文提到静态图的执行效率更高, 但是加速并不是一定的. 一般来说, 计算图越复杂, 加速效果越明显. 对于复杂的计算图,  比如训练深度学习模型, 获得的加速是巨大的. (译者注: 个人感觉还是要结合实际来看, 如果某一部分的计算既有复杂的计算图,  而计算图的复杂性又带来了额外的[内存消耗](https://link.zhihu.com/?target=https%3A//mxnet.incubator.apache.org/versions/master/architecture/note_memory.html) 或者计算量, 那么加速会比较明显, 但是很多时候, 比如一般的CNN模型, 主要计算量并不在于图的复杂性, 而在于卷积、矩阵乘法等操作, 加速并不会很明显. 此处想法有待验证)
>  

这个自动将python代码转成图表示代码的工具就叫做AutoGraph.

在TF 2.0中, 如果一个函数被`@tf.function`装饰了, 那么AutoGraph将会被自动调用, 从而将python函数转换成可执行的图表示.



#### tf.function的效率体现

```
import timeit

import tensorflow as tf

lstm_cell = tf.keras.layers.LSTMCell(10)
@tf.function
def fn(input,states):
    return lstm_cell(input,states)

input = tf.zeros([10,10])
states =[tf.zeros([10,10])] * 2

lstm_cell(input,states);
fn(input,states)

t1 = timeit.timeit(lambda:lstm_cell(input,states),number=1000)
print("耗时t1：",t1)
t2 = timeit.timeit(lambda:fn(input,states),number=1000)
print("耗时t2：",t2)

# 耗时t1： 0.6118525999999997
# 耗时t2： 0.39783360000000023
可以看出使用@tf.function 构造计算图运算时间消耗上会更小
```

# 2021-10-11

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190723133055850.jpg#pic_center)

## 早

### TensorBoard计算图谱可视化

[(19条消息) tf好朋友之tensorboard的使用_Bubbliiiing的学习小课堂-CSDN博客](https://blog.csdn.net/weixin_44791964/article/details/96633035?ops_request_misc=%7B%22request%5Fid%22%3A%22163392295616780271551621%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=163392295616780271551621&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_v29-2-96633035.pc_v2_rank_blog_default&utm_term=Tensorboard&spm=1018.2226.3001.4450)

[(19条消息) 神经网络学习小记录43——Keras中Tensorboard的使用_Bubbliiiing的学习小课堂-CSDN博客](https://blog.csdn.net/weixin_44791964/article/details/105002793?ops_request_misc=%7B%22request%5Fid%22%3A%22163392293616780274139874%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=163392293616780274139874&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_v29-1-105002793.pc_v2_rank_blog_default&utm_term=Keras+Tensorboard可视化工具&spm=1018.2226.3001.4450)



#### 知识相关储备

##### 1、tf.name_scope():   给计算图'graph'分组。

命名空间其实就是给几个变量包一层名字，方便变量管理。函数是：`tf.name_scope`
 另外，就像操作系统文件夹命名一样，不同的顶层文件夹下，可以有同名文件夹。这里，不同的命名空间下，可以有名字相同的变量。



就是，在神经网络设计时，我们往往都是使用顺序网络结构，不在乎各个层网络的归属关系，若是没添加网络层与层之间的归属约束，那么在使用tensorboard进行网络结果可视化时，就会发现各个层节点之间杂乱。为了更清楚区分各个层的层次以及层内变量归属，引入了命名空间约束这个API，就是把在这个约束下的网络打包成一个工作区，就像是创建文件夹，把属于该种内容下的组件放入文件夹内管理，以区分不同部件之间的归属，条理更清晰。同样文件夹里面可以有子文件夹，命名空间name_scope()也可以嵌套子命名空间。



###### 没使用name_scope进行约束

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211011092947802.png" alt="image-20211011092947802" style="zoom: 80%;" />

###### 使用了name_scope()约束

<img src="C:\Users\intel\AppData\Roaming\Typora\typora-user-images\image-20211011092813840.png" alt="image-20211011092813840" style="zoom: 33%;" />



##### 2、tensorboard 计算结构图符号及意义



![img](https://img-blog.csdn.net/20161102102201570?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)





#### **旧版TF1.X Tensorboard的可视化过程**

（1）首先肯定是先建立一个graph,你想从这个graph中获取某些数据的信息



（2）确定要在graph中的哪些节点放置summary operations以记录信息 
 使用tf.summary.scalar记录标量 
 使用tf.summary.histogram记录数据的直方图 
 使用tf.summary.distribution记录数据的分布图 
 使用tf.summary.image记录图像数据 
 ….

（3）operations并不会去真的执行计算，除非你告诉他们需要去run,或者它被其他的需要run的operation所依赖。而我们上一步创建的这些summary  operations其实并不被其他节点依赖，因此，我们需要特地去运行所有的summary节点。但是呢，一份程序下来可能有超多这样的summary  节点，要手动一个一个去启动自然是及其繁琐的，因此我们可以使用tf.summary.merge_all去将所有summary节点合并成一个节点，只要运行这个节点，就能产生所有我们之前设置的summary data。

（4）使用tf.summary.FileWriter将运行后输出的数据都保存到本地磁盘中

（5）运行整个程序，并在命令行输入运行tensorboard的指令，之后打开web端可查看可视化的结果  tensorboard --logdir=logs 



#### 新版Tensorboard的可视化过程

参考：https://www.tensorflow.org/tensorboard/get_started

TF2.X  中使用回调函数的方式来使用tensorboard，**tensorboard_callback** ---->[Keras TensorBoard 回调](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)

TensorBoard 是 TensorFlow 提供的可视化工具。

此回调记录 TensorBoard 的事件，包括：

- 指标汇总图
- 训练图可视化
- 激活直方图
- 采样分析

```
tf.keras.callbacks.TensorBoard(
    log_dir='logs', histogram_freq=0, write_graph=True,
    write_images=False, write_steps_per_second=False, update_freq='epoch',
    profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs
)
```

| 参数                     |                                                              |
| :----------------------- | ------------------------------------------------------------ |
| `log_dir`                | TensorBoard 解析的日志文件所在的目录路径。例如 log_dir = os.path.join(working_dir, 'logs') 该目录不应被任何其他回调重用。 |
| `histogram_freq`         | 计算模型层的激活和权重直方图的频率（以时期为单位）。如果设置为 0，则不会计算直方图。必须为直方图可视化指定验证数据（或拆分）。 |
| `write_graph`            | 是否在 TensorBoard 中可视化图形。当 write_graph 设置为 True 时，日志文件会变得非常大。 |
| `write_images`           | 是否编写模型权重以在 TensorBoard 中可视化为图像。            |
| `write_steps_per_second` | 是否将每秒的训练步骤记录到 Tensorboard 中。这支持纪元和批次频率记录。 |
| `update_freq`            | `'batch'`或`'epoch'`或整数。使用时`'batch'`，在每批之后将损失和指标写入 TensorBoard。这同样适用于`'epoch'`。如果使用整数，比方说`1000`，回调将每 1000 个批次将指标和损失写入 TensorBoard。请注意，过于频繁地写入 TensorBoard 会减慢您的训练速度。 |
| `profile_batch`          | 分析批次以采样计算特性。profile_batch 必须是非负整数或整数元组。一对正整数表示要分析的批次范围。默认情况下，它将分析第二批。设置 profile_batch=0 以禁用分析。 |
| `embeddings_freq`        | 嵌入层可视化的频率（以时期为单位）。如果设置为 0，嵌入将不会被可视化。 |
| `embeddings_metadata`    | 将嵌入层名称映射到文件的文件名的字典，用于保存嵌入层的元数据。如果所有嵌入层都使用相同的元数据文件，则可以传递单个文件名。 |















